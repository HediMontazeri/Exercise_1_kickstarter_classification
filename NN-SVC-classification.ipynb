{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from collections import Counter\n",
    "import scipy.stats as ss\n",
    "from sklearn import preprocessing,model_selection\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from sklearn.svm import LinearSVC\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ml_assignment_data_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing the data \n",
    "changing categorical variables to numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "df['category_id'] = le.fit_transform(df.category.astype(str))\n",
    "df['main_category_id'] = le.fit_transform(df.main_category.astype(str))\n",
    "df['currency_id'] = le.fit_transform(df.currency.astype(str))\n",
    "df['country_id'] = le.fit_transform(df.country.astype(str))\n",
    "df['new_state_id'] = le.fit_transform(df.new_state.astype(str))\n",
    "\n",
    "df['log_usd_goal_real'] = np.log(df['usd_goal_real']+1)\n",
    "df['log_goal'] = np.log(df['goal']+1)\n",
    "\n",
    "#dealing with date type\n",
    "df['launched_date'], df['launched_hour'] = df['launched'].str.split(' ',2).str\n",
    "df['launched_date'] = pd.to_datetime(df['launched_date'])\n",
    "df['deadline'] = pd.to_datetime(df['deadline'])\n",
    "# difference between deadline and lunched\n",
    "df['time_interval'] = df['launched_date'] - df['deadline']\n",
    "# changing that to int\n",
    "df['time_interval'] = df['time_interval'].dt.days\n",
    "#extracting yead and month and day from deadline to see if there are seasonal effect \n",
    "df['deadline_year'] = df['deadline'].dt.year\n",
    "df['deadline_month'] = df['deadline'].dt.month\n",
    "df['deadline_day'] = df['deadline'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing features and labels for SVM. The difference is that the feature shouldn't change to a dummy variable  \n",
    "X = df[['main_category_id', 'category_id', 'backers','country_id','deadline_day', 'deadline_month','time_interval']]\n",
    "X = np.array(X)\n",
    "y = df['new_state_id']\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y,test_size = 0.2)\n",
    "clfsvm = LinearSVC().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy 0.5756121165198878\n"
     ]
    }
   ],
   "source": [
    "print('SVM Accuracy',clfsvm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing features and labels for SVM. The difference is that the feature shouldn't change to a dummy variable  \n",
    "X = df[['main_category_id', 'category_id', 'backers','country_id', 'currency_id', 'deadline_day','deadline_month','deadline_day' ,'time_interval', 'log_usd_goal_real' ]]\n",
    "X = np.array(X)\n",
    "y = df['new_state_id']\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y,test_size= 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf_tree = tree.DecisionTreeClassifier()\n",
    "clf_tree = clf_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7905932449433852"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#changing the lable to a dummy variable. \n",
    "new_state_dummy = np_utils.to_categorical(df['new_state_id'])\n",
    "new_state_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### spliting date to features and label, also to test and train\n",
    "we don't need all variables to be included in the model. \n",
    "For instance, features such as dealine_year, log_usd_goal_real drop the accuracy of the model. Also, since we have the time interval and dealine, adding launched date is a duplicate. currency and country represent same thing. Therefore, on is enough. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['main_category_id', 'category_id', 'backers','country_id','deadline_day', 'deadline_month', 'time_interval']]\n",
    "X = np.array(X)\n",
    "y = new_state_dummy\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y,test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is usually common to rescale all variables to 0,1 in neural networks. Although in this case, it doesn't improve\n",
    "# network accuracy. Since most of variables' scale are similar, I ignored this part. \n",
    "\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# np_scaled = min_max_scaler.fit_transform(X_train.astype(float))\n",
    "# X_train_normalized = pd.DataFrame(np_scaled)\n",
    "# np_scaled = min_max_scaler.fit_transform(X_test.astype(float))\n",
    "# X_test_normalized = pd.DataFrame(np_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 206660 samples, validate on 51665 samples\n",
      "Epoch 1/20\n",
      "206660/206660 [==============================] - 4s 18us/step - loss: 0.4949 - acc: 0.7824 - val_loss: 0.4297 - val_acc: 0.8162\n",
      "Epoch 2/20\n",
      "206660/206660 [==============================] - 3s 12us/step - loss: 0.4242 - acc: 0.8168 - val_loss: 0.4098 - val_acc: 0.8277\n",
      "Epoch 3/20\n",
      "206660/206660 [==============================] - 2s 12us/step - loss: 0.4119 - acc: 0.8238 - val_loss: 0.4223 - val_acc: 0.8160\n",
      "Epoch 4/20\n",
      "206660/206660 [==============================] - 3s 13us/step - loss: 0.4037 - acc: 0.8267 - val_loss: 0.3914 - val_acc: 0.8340\n",
      "Epoch 5/20\n",
      "206660/206660 [==============================] - 3s 12us/step - loss: 0.4005 - acc: 0.8292 - val_loss: 0.3912 - val_acc: 0.8326\n",
      "Epoch 6/20\n",
      "206660/206660 [==============================] - 3s 13us/step - loss: 0.3962 - acc: 0.8314 - val_loss: 0.3886 - val_acc: 0.8351\n",
      "Epoch 7/20\n",
      "206660/206660 [==============================] - 2s 12us/step - loss: 0.3909 - acc: 0.8349 - val_loss: 0.3845 - val_acc: 0.8381\n",
      "Epoch 8/20\n",
      "206660/206660 [==============================] - 3s 15us/step - loss: 0.3940 - acc: 0.8324 - val_loss: 0.4142 - val_acc: 0.8185\n",
      "Epoch 9/20\n",
      "206660/206660 [==============================] - 2s 12us/step - loss: 0.3918 - acc: 0.8339 - val_loss: 0.3971 - val_acc: 0.8267\n",
      "Epoch 10/20\n",
      "206660/206660 [==============================] - 3s 14us/step - loss: 0.3891 - acc: 0.8346 - val_loss: 0.3818 - val_acc: 0.8392\n",
      "Epoch 11/20\n",
      "206660/206660 [==============================] - 3s 14us/step - loss: 0.3881 - acc: 0.8359 - val_loss: 0.3890 - val_acc: 0.8339\n",
      "Epoch 12/20\n",
      "206660/206660 [==============================] - 3s 15us/step - loss: 0.3856 - acc: 0.8362 - val_loss: 0.3775 - val_acc: 0.8429\n",
      "Epoch 13/20\n",
      "206660/206660 [==============================] - 2s 12us/step - loss: 0.3863 - acc: 0.8368 - val_loss: 0.4533 - val_acc: 0.7934\n",
      "Epoch 14/20\n",
      "206660/206660 [==============================] - 3s 15us/step - loss: 0.3849 - acc: 0.8373 - val_loss: 0.3773 - val_acc: 0.8431\n",
      "Epoch 15/20\n",
      "206660/206660 [==============================] - 3s 12us/step - loss: 0.3823 - acc: 0.8390 - val_loss: 0.3857 - val_acc: 0.8336\n",
      "Epoch 16/20\n",
      "206660/206660 [==============================] - 3s 12us/step - loss: 0.3825 - acc: 0.8379 - val_loss: 0.3762 - val_acc: 0.8429\n",
      "Epoch 17/20\n",
      "206660/206660 [==============================] - 3s 13us/step - loss: 0.3836 - acc: 0.8373 - val_loss: 0.3851 - val_acc: 0.8349\n",
      "Epoch 18/20\n",
      "206660/206660 [==============================] - 4s 17us/step - loss: 0.3830 - acc: 0.8382 - val_loss: 0.3833 - val_acc: 0.8370\n",
      "Epoch 19/20\n",
      "206660/206660 [==============================] - 3s 14us/step - loss: 0.3810 - acc: 0.8387 - val_loss: 0.3739 - val_acc: 0.8447\n",
      "Epoch 20/20\n",
      "206660/206660 [==============================] - 3s 13us/step - loss: 0.3786 - acc: 0.8408 - val_loss: 0.3733 - val_acc: 0.8427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x1a43fcdf98>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "model01 = keras.Sequential([\n",
    "    keras.layers.Dense(70, input_dim = 7, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(40, activation = tf.nn.tanh),\n",
    "    #keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(30, activation = tf.nn.tanh),\n",
    "    keras.layers.Dense(3, activation = tf.nn.softmax),\n",
    "    ])\n",
    "model01.compile(optimizer = tf.train.AdamOptimizer(),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "model01.fit(X_train, y_train, validation_data=(X_test,y_test), batch_size= 300, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on the part of data that the network hasn't seen yet.\n",
    "results = model01.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the prediction from array to a data frame\n",
    "results = pd.DataFrame({'column1':results[:,0],'column2':results[:,1],'column3':results[:,2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each label is predicted a number between 0, 1. max of 3 columns shows the prediction.\n",
    "results['max'] = results.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column1</th>\n",
       "      <th>column2</th>\n",
       "      <th>column3</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027168</td>\n",
       "      <td>5.262653e-01</td>\n",
       "      <td>4.465669e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.748091</td>\n",
       "      <td>2.476361e-01</td>\n",
       "      <td>4.272917e-03</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040971</td>\n",
       "      <td>7.518923e-01</td>\n",
       "      <td>2.071370e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.195272</td>\n",
       "      <td>6.492521e-01</td>\n",
       "      <td>1.554759e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.997744</td>\n",
       "      <td>2.208908e-03</td>\n",
       "      <td>4.747870e-05</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.131149</td>\n",
       "      <td>7.407973e-01</td>\n",
       "      <td>1.280532e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.024869</td>\n",
       "      <td>6.843339e-01</td>\n",
       "      <td>2.907973e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.054301</td>\n",
       "      <td>7.641478e-01</td>\n",
       "      <td>1.815509e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.209492</td>\n",
       "      <td>5.975983e-01</td>\n",
       "      <td>1.929092e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.999986</td>\n",
       "      <td>1.404071e-05</td>\n",
       "      <td>2.747967e-08</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.999804</td>\n",
       "      <td>1.950477e-04</td>\n",
       "      <td>9.942130e-07</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.050834</td>\n",
       "      <td>8.533904e-01</td>\n",
       "      <td>9.577551e-02</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.088630</td>\n",
       "      <td>6.242347e-01</td>\n",
       "      <td>2.871356e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.035644</td>\n",
       "      <td>7.648406e-01</td>\n",
       "      <td>1.995150e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.055638</td>\n",
       "      <td>5.903673e-01</td>\n",
       "      <td>3.539950e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.992110</td>\n",
       "      <td>7.780014e-03</td>\n",
       "      <td>1.097795e-04</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.016893</td>\n",
       "      <td>4.440566e-01</td>\n",
       "      <td>5.390505e-01</td>\n",
       "      <td>column3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.005336</td>\n",
       "      <td>3.635359e-01</td>\n",
       "      <td>6.311280e-01</td>\n",
       "      <td>column3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.058373</td>\n",
       "      <td>6.838802e-01</td>\n",
       "      <td>2.577465e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.038472</td>\n",
       "      <td>7.414406e-01</td>\n",
       "      <td>2.200877e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.058607</td>\n",
       "      <td>6.411924e-01</td>\n",
       "      <td>3.002005e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.999433</td>\n",
       "      <td>5.470116e-04</td>\n",
       "      <td>2.008663e-05</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.153612</td>\n",
       "      <td>7.411970e-01</td>\n",
       "      <td>1.051911e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.999022</td>\n",
       "      <td>9.732557e-04</td>\n",
       "      <td>4.532720e-06</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.003283</td>\n",
       "      <td>3.485400e-01</td>\n",
       "      <td>6.481766e-01</td>\n",
       "      <td>column3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.999663</td>\n",
       "      <td>3.342278e-04</td>\n",
       "      <td>3.131971e-06</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.741165</td>\n",
       "      <td>2.480176e-01</td>\n",
       "      <td>1.081746e-02</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.030235</td>\n",
       "      <td>4.843701e-01</td>\n",
       "      <td>4.853951e-01</td>\n",
       "      <td>column3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.998947</td>\n",
       "      <td>1.032058e-03</td>\n",
       "      <td>2.076033e-05</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.995010</td>\n",
       "      <td>4.945790e-03</td>\n",
       "      <td>4.383002e-05</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51635</th>\n",
       "      <td>0.124769</td>\n",
       "      <td>5.549664e-01</td>\n",
       "      <td>3.202642e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51636</th>\n",
       "      <td>0.965049</td>\n",
       "      <td>3.470399e-02</td>\n",
       "      <td>2.466268e-04</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51637</th>\n",
       "      <td>0.419192</td>\n",
       "      <td>5.642974e-01</td>\n",
       "      <td>1.651057e-02</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51638</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>5.685215e-07</td>\n",
       "      <td>3.147314e-10</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51639</th>\n",
       "      <td>0.473184</td>\n",
       "      <td>5.083148e-01</td>\n",
       "      <td>1.850118e-02</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51640</th>\n",
       "      <td>0.999807</td>\n",
       "      <td>1.904505e-04</td>\n",
       "      <td>2.234432e-06</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51641</th>\n",
       "      <td>0.035829</td>\n",
       "      <td>6.945167e-01</td>\n",
       "      <td>2.696547e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51642</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.909965e-07</td>\n",
       "      <td>2.352620e-11</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51643</th>\n",
       "      <td>0.034132</td>\n",
       "      <td>7.055914e-01</td>\n",
       "      <td>2.602769e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51644</th>\n",
       "      <td>0.999493</td>\n",
       "      <td>4.894364e-04</td>\n",
       "      <td>1.734514e-05</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51645</th>\n",
       "      <td>0.928694</td>\n",
       "      <td>6.335842e-02</td>\n",
       "      <td>7.947151e-03</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51646</th>\n",
       "      <td>0.127470</td>\n",
       "      <td>8.114286e-01</td>\n",
       "      <td>6.110163e-02</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51647</th>\n",
       "      <td>0.209863</td>\n",
       "      <td>6.013339e-01</td>\n",
       "      <td>1.888034e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51648</th>\n",
       "      <td>0.124068</td>\n",
       "      <td>6.180198e-01</td>\n",
       "      <td>2.579119e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51649</th>\n",
       "      <td>0.999997</td>\n",
       "      <td>2.526498e-06</td>\n",
       "      <td>1.382753e-09</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51650</th>\n",
       "      <td>0.999995</td>\n",
       "      <td>4.939768e-06</td>\n",
       "      <td>1.945765e-09</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51651</th>\n",
       "      <td>0.999731</td>\n",
       "      <td>2.646727e-04</td>\n",
       "      <td>4.119293e-06</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51652</th>\n",
       "      <td>0.188986</td>\n",
       "      <td>6.111372e-01</td>\n",
       "      <td>1.998769e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51653</th>\n",
       "      <td>0.037353</td>\n",
       "      <td>7.313604e-01</td>\n",
       "      <td>2.312863e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51654</th>\n",
       "      <td>0.381505</td>\n",
       "      <td>5.981090e-01</td>\n",
       "      <td>2.038640e-02</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51655</th>\n",
       "      <td>0.094295</td>\n",
       "      <td>2.917073e-01</td>\n",
       "      <td>6.139982e-01</td>\n",
       "      <td>column3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51656</th>\n",
       "      <td>0.046743</td>\n",
       "      <td>7.758501e-01</td>\n",
       "      <td>1.774070e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51657</th>\n",
       "      <td>0.012332</td>\n",
       "      <td>5.931391e-01</td>\n",
       "      <td>3.945293e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51658</th>\n",
       "      <td>0.121538</td>\n",
       "      <td>6.702261e-01</td>\n",
       "      <td>2.082359e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51659</th>\n",
       "      <td>0.961734</td>\n",
       "      <td>3.731189e-02</td>\n",
       "      <td>9.544701e-04</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51660</th>\n",
       "      <td>0.344460</td>\n",
       "      <td>6.374999e-01</td>\n",
       "      <td>1.804041e-02</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51661</th>\n",
       "      <td>0.999994</td>\n",
       "      <td>5.899427e-06</td>\n",
       "      <td>4.539082e-09</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51662</th>\n",
       "      <td>0.133434</td>\n",
       "      <td>7.386468e-01</td>\n",
       "      <td>1.279191e-01</td>\n",
       "      <td>column2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51663</th>\n",
       "      <td>0.996959</td>\n",
       "      <td>2.968021e-03</td>\n",
       "      <td>7.262280e-05</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51664</th>\n",
       "      <td>0.999934</td>\n",
       "      <td>6.584216e-05</td>\n",
       "      <td>1.257520e-07</td>\n",
       "      <td>column1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51665 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        column1       column2       column3      max\n",
       "0      0.027168  5.262653e-01  4.465669e-01  column2\n",
       "1      0.748091  2.476361e-01  4.272917e-03  column1\n",
       "2      0.040971  7.518923e-01  2.071370e-01  column2\n",
       "3      0.195272  6.492521e-01  1.554759e-01  column2\n",
       "4      0.997744  2.208908e-03  4.747870e-05  column1\n",
       "5      0.131149  7.407973e-01  1.280532e-01  column2\n",
       "6      0.024869  6.843339e-01  2.907973e-01  column2\n",
       "7      0.054301  7.641478e-01  1.815509e-01  column2\n",
       "8      0.209492  5.975983e-01  1.929092e-01  column2\n",
       "9      0.999986  1.404071e-05  2.747967e-08  column1\n",
       "10     0.999804  1.950477e-04  9.942130e-07  column1\n",
       "11     0.050834  8.533904e-01  9.577551e-02  column2\n",
       "12     0.088630  6.242347e-01  2.871356e-01  column2\n",
       "13     0.035644  7.648406e-01  1.995150e-01  column2\n",
       "14     0.055638  5.903673e-01  3.539950e-01  column2\n",
       "15     0.992110  7.780014e-03  1.097795e-04  column1\n",
       "16     0.016893  4.440566e-01  5.390505e-01  column3\n",
       "17     0.005336  3.635359e-01  6.311280e-01  column3\n",
       "18     0.058373  6.838802e-01  2.577465e-01  column2\n",
       "19     0.038472  7.414406e-01  2.200877e-01  column2\n",
       "20     0.058607  6.411924e-01  3.002005e-01  column2\n",
       "21     0.999433  5.470116e-04  2.008663e-05  column1\n",
       "22     0.153612  7.411970e-01  1.051911e-01  column2\n",
       "23     0.999022  9.732557e-04  4.532720e-06  column1\n",
       "24     0.003283  3.485400e-01  6.481766e-01  column3\n",
       "25     0.999663  3.342278e-04  3.131971e-06  column1\n",
       "26     0.741165  2.480176e-01  1.081746e-02  column1\n",
       "27     0.030235  4.843701e-01  4.853951e-01  column3\n",
       "28     0.998947  1.032058e-03  2.076033e-05  column1\n",
       "29     0.995010  4.945790e-03  4.383002e-05  column1\n",
       "...         ...           ...           ...      ...\n",
       "51635  0.124769  5.549664e-01  3.202642e-01  column2\n",
       "51636  0.965049  3.470399e-02  2.466268e-04  column1\n",
       "51637  0.419192  5.642974e-01  1.651057e-02  column2\n",
       "51638  0.999999  5.685215e-07  3.147314e-10  column1\n",
       "51639  0.473184  5.083148e-01  1.850118e-02  column2\n",
       "51640  0.999807  1.904505e-04  2.234432e-06  column1\n",
       "51641  0.035829  6.945167e-01  2.696547e-01  column2\n",
       "51642  1.000000  2.909965e-07  2.352620e-11  column1\n",
       "51643  0.034132  7.055914e-01  2.602769e-01  column2\n",
       "51644  0.999493  4.894364e-04  1.734514e-05  column1\n",
       "51645  0.928694  6.335842e-02  7.947151e-03  column1\n",
       "51646  0.127470  8.114286e-01  6.110163e-02  column2\n",
       "51647  0.209863  6.013339e-01  1.888034e-01  column2\n",
       "51648  0.124068  6.180198e-01  2.579119e-01  column2\n",
       "51649  0.999997  2.526498e-06  1.382753e-09  column1\n",
       "51650  0.999995  4.939768e-06  1.945765e-09  column1\n",
       "51651  0.999731  2.646727e-04  4.119293e-06  column1\n",
       "51652  0.188986  6.111372e-01  1.998769e-01  column2\n",
       "51653  0.037353  7.313604e-01  2.312863e-01  column2\n",
       "51654  0.381505  5.981090e-01  2.038640e-02  column2\n",
       "51655  0.094295  2.917073e-01  6.139982e-01  column3\n",
       "51656  0.046743  7.758501e-01  1.774070e-01  column2\n",
       "51657  0.012332  5.931391e-01  3.945293e-01  column2\n",
       "51658  0.121538  6.702261e-01  2.082359e-01  column2\n",
       "51659  0.961734  3.731189e-02  9.544701e-04  column1\n",
       "51660  0.344460  6.374999e-01  1.804041e-02  column2\n",
       "51661  0.999994  5.899427e-06  4.539082e-09  column1\n",
       "51662  0.133434  7.386468e-01  1.279191e-01  column2\n",
       "51663  0.996959  2.968021e-03  7.262280e-05  column1\n",
       "51664  0.999934  6.584216e-05  1.257520e-07  column1\n",
       "\n",
       "[51665 rows x 4 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame({'column1':y_test[:,0],'column2':y_test[:,1],'column3':y_test[:,2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting to excel files\n",
    "results.to_excel('prediction_results.xlsx')\n",
    "y_test.to_excel('test.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
